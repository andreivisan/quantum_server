{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "df794958-3916-4ac7-99d2-a7bdee11479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "be504f8b-911d-4a20-83c1-b844dcca7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('system_prompt.txt', 'r') as file:\n",
    "    system_prompt = file.read()\n",
    "system_prompt = system_prompt.replace(\"{\", \"{{\").replace(\"}\", \"}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e97b47e9-b8c2-4fc1-a0b2-fcfaac9c5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepResponse(BaseModel):\n",
    "    title: str = Field(description=\"title of the step\")\n",
    "    content: str = Field(description=\"content of the step\")\n",
    "    confidence: str = Field(description=\"model confidence level for current step\")\n",
    "    next_action: str = Field(description=\"next action performed by the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0044c006-edf7-4840-ac41-b00812f4b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messages']\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=StepResponse)\n",
    "# Define the prompt template\n",
    "template = f\"\"\"{system_prompt}\n",
    "Messages: {{messages}}\n",
    "\"\"\"\n",
    "# Create the prompt\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "print(prompt.input_variables)\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "# Build the chain\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4512ba87-8c87-40b2-9269-8ceee4e11bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chain_of_thought(user_message, max_steps=10, confidence_threshold=99):\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_message),\n",
    "        AIMessage(content=\"Understood. I will now create a detailed reasoning chain following the given instructions, starting with a thorough problem decomposition.\")\n",
    "    ]\n",
    "\n",
    "    step_count = 1\n",
    "    total_thinking_time = 0\n",
    "\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            step_data = chain.invoke({\"messages\": messages})\n",
    "        except OutputParserException:\n",
    "            content = \"\"\n",
    "            step_data = {\n",
    "                \"title\": \"Raw Response\",\n",
    "                \"content\": content,\n",
    "                \"next_action\": \"continue\"\n",
    "            }\n",
    "        end_time = time.time()\n",
    "        thinking_time = end_time - start_time\n",
    "        total_thinking_time += thinking_time\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"content\": json.dumps(step_data)})\n",
    "        print(\"Next reasoning step: \", step_data[\"title\"])\n",
    "\n",
    "        if step_data[\"next_action\"].lower().strip() == \"final_answer\" or step_count > 10:\n",
    "            break\n",
    "\n",
    "        step_count += 1\n",
    "\n",
    "    # Request final answer\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please provide the final answer based on your reasoning above.\",\n",
    "        })\n",
    "        try:\n",
    "            final_data = chain.invoke({\"messages\": messages})\n",
    "            break\n",
    "        except Exception:\n",
    "            print(\"Error encountered while retrieving the final answer. Retrying...\")\n",
    "            continue\n",
    "    end_time = time.time()\n",
    "    thinking_time = end_time - start_time\n",
    "    total_thinking_time += thinking_time\n",
    "\n",
    "    return final_data[\"content\"], total_thinking_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c6080eae-c185-4e7c-8d3c-553a11bf7da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next reasoning step:  Understanding the Problem\n",
      "Next reasoning step:  Breaking Down the Problem\n",
      "Next reasoning step:  Understanding the Problem\n",
      "Next reasoning step:  Analyzing Phonetic Patterns\n",
      "Next reasoning step:  Identifying Phonetic Patterns\n",
      "Next reasoning step:  Phonetic Breakdown Analysis\n"
     ]
    }
   ],
   "source": [
    "user_message = \"how many r's are in strawberry\"\n",
    "final_resp, total_time = generate_chain_of_thought(user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f971f721-9a5f-45be-bda6-877d0c975ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To analyze the phonetic breakdown of the word 'strawberry', I'll consider the sounds and patterns in the English language. In English, words can be broken down into their individual phonemes, which are the basic units of sound. The word 'strawberry' is pronounced as /strow berry/, where the stress falls on the first syllable. This means that the letter 'r' appears at the end of each syllable, with the exception of the first syllable, which does not contain an 'r'. Therefore, we can expect two 'r's to appear in the word, one after the vowel sound in the second syllable and another after the vowel sound in the third syllable.\n",
      "Total Thinking Time: 14.40 seconds\n"
     ]
    }
   ],
   "source": [
    "# Print the steps\n",
    "print(final_resp)\n",
    "print(f\"Total Thinking Time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1dfc06-a96a-4d76-b163-e95356441c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
