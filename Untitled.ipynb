{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4852fe46-b6ad-4134-858c-67096f8eb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Topological Sorting Essentials\",\n",
      "  \"content\": \"To achieve 80% benefits with only 20% effort, focus on these key topics: 1. Understanding Graph Theory Basics (5%): Learn the fundamentals of graph theory, including nodes, edges, and their relationships. 2. Topological Sorting Algorithms (10%): Familiarize yourself with popular topological sorting algorithms like Depth-First Search (DFS) and Breadth-First Search (BFS). 3. Graph Representations (5%): Understand how to represent graphs, including adjacency matrices and edge lists. 4. Graph Traversal Techniques (10%): Learn about graph traversal techniques like DFS and BFS, which are essential for topological sorting. 5. Practice with Real-World Examples (10%): Apply your knowledge to real-world examples to gain practical experience and improve your understanding of the concepts. By mastering these 5 topics, you'll have a solid foundation in topological sorting and be able to tackle more complex problems with ease.\",\n",
      "  \"confidence\": 95,\n",
      "  \"next_action\": \"final_answer\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.chains.base import Chain\n",
    "import json\n",
    "\n",
    "class CustomCoTParser(BaseOutputParser):\n",
    "    \"\"\"\n",
    "    A robust output parser for handling Tree of Thought (ToT) reasoning steps.\n",
    "    \"\"\"\n",
    "    def clean_response(self, output: str) -> str:\n",
    "        \"\"\"Sanitize and clean the raw response to ensure valid JSON formatting.\"\"\"\n",
    "        output = output.strip()  # Remove leading and trailing whitespace\n",
    "        if \"%\" in output:\n",
    "            output = output.replace(\"%\", \"\")  # Remove percentage signs\n",
    "        if output.startswith(\"{\") and output.endswith(\"}\"):\n",
    "            output = output.replace(\"\\n\", \"\").replace(\"\\\\n\", \"\")  # Replace newlines\n",
    "        return output\n",
    "\n",
    "    def validate_response(self, parsed_output: dict) -> dict:\n",
    "        \"\"\"Ensure the parsed response has the required fields.\"\"\"\n",
    "        required_keys = {\"title\", \"content\", \"next_action\"}\n",
    "        for key in required_keys:\n",
    "            if key not in parsed_output:\n",
    "                raise ValueError(f\"Missing required field: {key}\")\n",
    "        return parsed_output\n",
    "\n",
    "    def parse_old(self, output: str):\n",
    "        \"\"\"Parse and validate the output.\"\"\"\n",
    "        try:\n",
    "            cleaned_output = self.clean_response(output)\n",
    "            parsed_output = json.loads(cleaned_output)\n",
    "            return self.validate_response(parsed_output)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON: {output}\")\n",
    "            return {\n",
    "                \"title\": \"Fallback Reasoning\",\n",
    "                \"content\": \"Unable to parse a valid response. Please clarify.\",\n",
    "                \"confidence\": 50,\n",
    "                \"next_action\": \"continue\",\n",
    "            }\n",
    "        except ValueError as ve:\n",
    "            print(f\"Validation error: {ve}\")\n",
    "            return {\n",
    "                \"title\": \"Fallback Reasoning\",\n",
    "                \"content\": str(ve),\n",
    "                \"confidence\": 50,\n",
    "                \"next_action\": \"continue\",\n",
    "            }\n",
    "    def parse(self, output: str):\n",
    "        try:\n",
    "            # Clean the output by stripping unnecessary whitespace and ensuring proper JSON formatting\n",
    "            cleaned_output = output.strip()\n",
    "            if cleaned_output.startswith(\"{\") and cleaned_output.endswith(\"}\"):\n",
    "                cleaned_output = cleaned_output.replace(\"\\n\", \" \")  # Replace newlines with spaces for JSON compatibility\n",
    "\n",
    "            # Parse the cleaned JSON string\n",
    "            parsed_output = json.loads(cleaned_output)\n",
    "\n",
    "            # Validate the required keys\n",
    "            required_keys = {\"title\", \"content\", \"next_action\"}\n",
    "            if not required_keys.issubset(parsed_output):\n",
    "                raise ValueError(f\"Response is missing required keys: {required_keys - parsed_output.keys()}\")\n",
    "\n",
    "            return parsed_output\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {output}. Error: {e}\")\n",
    "            return {\n",
    "                \"title\": \"Fallback Reasoning\",\n",
    "                \"content\": \"Unable to parse valid JSON. Please clarify your response.\",\n",
    "                \"confidence\": 50,\n",
    "                \"next_action\": \"continue\",\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error in parsing response: {output}. Error: {e}\")\n",
    "            return {\n",
    "                \"title\": \"Fallback Reasoning\",\n",
    "                \"content\": \"An unexpected error occurred while processing the response.\",\n",
    "                \"confidence\": 50,\n",
    "                \"next_action\": \"continue\",\n",
    "            }\n",
    "\n",
    "# Define the system prompt to enforce Tree of Thought reasoning\n",
    "system_prompt = '''\n",
    "You are an expert AI assistant that creates advanced reasoning trees. For each branch:\n",
    "1. Clearly progress towards exploring alternative solutions.\n",
    "2. Avoid repeating the same content across branches.\n",
    "3. Use diverse approaches to reason through sub-problems.\n",
    "4. Stop when an optimal or final answer is reached or after a maximum of 10 steps.\n",
    "5. Ensure each step's \"next_action\" field logically follows from the step's \"content\".\n",
    "\n",
    "Example Query: \"How many R's are in the word 'strawberry'?\"\n",
    "Example Response:\n",
    "{{\n",
    "  \"title\": \"Counting R's in 'strawberry'\",\n",
    "  \"content\": \"The word 'strawberry' contains the letters S-T-R-A-W-B-E-R-R-Y. Counting the R's, we find there are 3 R's in this word.\",\n",
    "  \"confidence\": 95,\n",
    "  \"next_action\": \"final_answer\"\n",
    "}}\n",
    "\n",
    "Example Query: \"Write a Hello World program in Java.\"\n",
    "Example Response:\n",
    "{{\n",
    "  \"title\": \"Java Hello World Program\",\n",
    "  \"content\": \"Here is the code:\\npublic class HelloWorld {{\\n  public static void main(String[] args) {{\\n    System.out.println(\\\"Hello, World!\\\");\\n  }}\\n}}\",\n",
    "  \"confidence\": 95,\n",
    "  \"next_action\": \"final_answer\"\n",
    "}}\n",
    "\n",
    "MOST IMPORTANT: Respond in JSON format with 'title', 'content', 'confidence' (0-100), and 'next_action' ('continue' or 'final_answer') keys.\n",
    "REPLY WITH EXACTLY ONE JSON OBJECT THAT REPRESENTS EXACTLY ONE STEP IN YOUR REASONING.\n",
    "\n",
    "Example of a valid JSON response:\n",
    "{{\n",
    "    \"title\": \"Initial Problem Analysis\",\n",
    "    \"content\": \"To begin solving this problem, I'll break it down into its core components...\",\n",
    "    \"confidence\": 90,\n",
    "    \"next_action\": \"continue\"\n",
    "}}\n",
    "'''\n",
    "\n",
    "# Define the template and chain for enforcing CoT reasoning\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input_query\"],\n",
    "    template=system_prompt + \"\\nUser Query: {input_query}\"\n",
    ")\n",
    "\n",
    "local_llm = OllamaLLM(model=\"codeup\", temperature=0.2)\n",
    "\n",
    "# Updated chain configuration using pipe separator\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# Updated chain configuration using ToT\n",
    "class ToTChain(Chain):\n",
    "    \"\"\"Custom chain for handling Tree of Thought responses.\"\"\"\n",
    "    prompt: PromptTemplate\n",
    "    llm: OllamaLLM\n",
    "\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"input_query\"]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self):\n",
    "        return [\"output\"]\n",
    "\n",
    "    def _call(self, inputs: dict):\n",
    "        formatted_prompt = self.prompt.format(input_query=inputs[\"input_query\"])\n",
    "        response = self.llm.invoke(formatted_prompt)\n",
    "        return {\"output\": response}\n",
    "\n",
    "    def invoke(self, inputs: dict):\n",
    "        return self._call(inputs)\n",
    "\n",
    "# Iterative Chain of Thought Reasoning\n",
    "cot_chain = ToTChain(prompt=prompt_template, llm=local_llm)\n",
    "\n",
    "def run_tot_chain(query, max_steps=10):\n",
    "    branches = []\n",
    "    current_query = query\n",
    "    seen_responses = set()\n",
    "    context = []  # To store the reasoning context\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        # Incorporate accumulated context into the query\n",
    "        if context:\n",
    "            context_string = \" \".join([branch[\"content\"] for branch in context[-3:]])  # Use the last 3 steps for brevity\n",
    "            query_with_context = f\"{context_string} Based on this, {current_query}\"\n",
    "        else:\n",
    "            query_with_context = current_query\n",
    "\n",
    "        result = cot_chain.invoke({\"input_query\": query_with_context})\n",
    "        try:\n",
    "            # Parse the model response\n",
    "            parser = CustomCoTParser()\n",
    "            parsed_result = parser.parse(result[\"output\"])\n",
    "\n",
    "            # Append the parsed step to the reasoning tree\n",
    "            branches.append(parsed_result)\n",
    "\n",
    "            # Add high-confidence branches to the context\n",
    "            if parsed_result.get(\"confidence\", 0) > 80:\n",
    "                context.append(parsed_result)\n",
    "\n",
    "            # Check for the final answer\n",
    "            if parsed_result.get(\"next_action\") == \"final_answer\":\n",
    "                break\n",
    "\n",
    "            # Avoid loops by detecting repetition\n",
    "            if parsed_result[\"content\"] in seen_responses:\n",
    "                current_query = \"Please refine and provide the final answer based on your reasoning above.\"\n",
    "            else:\n",
    "                seen_responses.add(parsed_result[\"content\"])\n",
    "                current_query = parsed_result[\"content\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle unexpected errors gracefully\n",
    "            print(f\"Error during processing: {e}\")\n",
    "            fallback_content = f\"Fallback: Unable to process response. Error: {e}\"\n",
    "            branches.append({\n",
    "                \"title\": \"Fallback Reasoning\",\n",
    "                \"content\": fallback_content,\n",
    "                \"confidence\": 50,\n",
    "                \"next_action\": \"continue\",\n",
    "            })\n",
    "            current_query = \"Please refine and provide the final answer based on your reasoning above.\"\n",
    "\n",
    "    # Aggregate final results from high-confidence branches\n",
    "    final_results = [branch for branch in branches if branch.get(\"confidence\", 0) > 80]\n",
    "\n",
    "    # Synthesize branches into a comprehensive final answer if possible\n",
    "    if len(final_results) > 1:\n",
    "        combined_content = \" \".join([branch[\"content\"] for branch in final_results])\n",
    "        final_results.append({\n",
    "            \"title\": \"Comprehensive Final Answer\",\n",
    "            \"content\": combined_content,\n",
    "            \"confidence\": 100,\n",
    "            \"next_action\": \"done\",\n",
    "        })\n",
    "\n",
    "    return final_results if final_results else branches\n",
    "\n",
    "# Test the chain\n",
    "query = \"what is the 20% I need to learn that can give me the 80% benefits for topological sort. Provide a list of topics\"\n",
    "response_branches = run_tot_chain(query)\n",
    "for branch in response_branches:\n",
    "    print(json.dumps(branch, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be5e35-c4f9-40ff-aa1c-868dee74347d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
