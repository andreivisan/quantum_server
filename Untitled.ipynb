{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4852fe46-b6ad-4134-858c-67096f8eb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response: {'output': '\\n{\\n  \"title\": \"Python Hello World Program\",\\n  \"content\": \"Here is the code:\\nprint(\\\\\"Hello, World!\\\\\")\\n\",\\n  \"confidence\": 95,\\n  \"next_action\": \"final_answer\"\\n}'}\n",
      "Error parsing response: {'output': '\\nPlease provide the final answer based on your reasoning above.'}\n",
      "Error parsing response: {'output': '\\nPlease find my response below:\\n\\n{\\n  \"title\": \"Final Answer\",\\n  \"content\": \"The word \\'strawberry\\' contains 3 R\\'s.\",\\n  \"confidence\": 95,\\n  \"next_action\": \"final_answer\"\\n}'}\n",
      "Error parsing response: {'output': '\\nPlease provide the final answer based on your reasoning above.'}\n",
      "{\n",
      "  \"title\": \"Final Answer\",\n",
      "  \"content\": \"The word 'strawberry' contains 3 R's.\",\n",
      "  \"confidence\": 95,\n",
      "  \"next_action\": \"final_answer\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.chains.base import Chain\n",
    "import json\n",
    "\n",
    "class CustomCoTParser(BaseOutputParser):\n",
    "    \"\"\"\n",
    "    A custom output parser for forcing Chain of Thought (CoT) reasoning steps.\n",
    "    \"\"\"\n",
    "    def parse(self, output: str):\n",
    "        # Parse JSON-formatted CoT response\n",
    "        try:\n",
    "            parsed_output = json.loads(output)\n",
    "            return parsed_output\n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback to partial extraction of content and next action if JSON fails\n",
    "            if \"content\" in output and \"next_action\" in output:\n",
    "                return {\n",
    "                    \"title\": \"Fallback Reasoning\",\n",
    "                    \"content\": output.split(\"\\ncontent: \")[1].split(\"\\n\")[0],\n",
    "                    \"confidence\": 50,\n",
    "                    \"next_action\": \"continue\"\n",
    "                }\n",
    "            raise ValueError(\"Invalid response format. Expected JSON or partial structure.\")\n",
    "\n",
    "# Define the system prompt to enforce Tree of Thought reasoning\n",
    "system_prompt = '''\n",
    "You are an expert AI assistant that creates advanced reasoning trees. For each branch:\n",
    "1. Clearly progress towards exploring alternative solutions.\n",
    "2. Avoid repeating the same content across branches.\n",
    "3. Use diverse approaches to reason through sub-problems.\n",
    "4. Stop when an optimal or final answer is reached or after a maximum of 10 steps.\n",
    "5. Ensure each step's \"next_action\" field logically follows from the step's \"content\".\n",
    "\n",
    "Example Query: \"How many R's are in the word 'strawberry'?\"\n",
    "Example Response:\n",
    "{{\n",
    "  \"title\": \"Counting R's in 'strawberry'\",\n",
    "  \"content\": \"The word 'strawberry' contains the letters S-T-R-A-W-B-E-R-R-Y. Counting the R's, we find there are 3 R's in this word.\",\n",
    "  \"confidence\": 95,\n",
    "  \"next_action\": \"final_answer\"\n",
    "}}\n",
    "\n",
    "Example Query: \"Write a Hello World program in Java.\"\n",
    "Example Response:\n",
    "{{\n",
    "  \"title\": \"Java Hello World Program\",\n",
    "  \"content\": \"Here is the code:\\npublic class HelloWorld {{\\n  public static void main(String[] args) {{\\n    System.out.println(\\\"Hello, World!\\\");\\n  }}\\n}}\",\n",
    "  \"confidence\": 95,\n",
    "  \"next_action\": \"final_answer\"\n",
    "}}\n",
    "\n",
    "MOST IMPORTANT: Respond in JSON format with 'title', 'content', 'confidence' (0-100), and 'next_action' ('continue' or 'final_answer') keys.\n",
    "REPLY WITH EXACTLY ONE JSON OBJECT THAT REPRESENTS EXACTLY ONE STEP IN YOUR REASONING.\n",
    "\n",
    "Example of a valid JSON response:\n",
    "{{\n",
    "    \"title\": \"Initial Problem Analysis\",\n",
    "    \"content\": \"To begin solving this problem, I'll break it down into its core components...\",\n",
    "    \"confidence\": 90,\n",
    "    \"next_action\": \"continue\"\n",
    "}}\n",
    "'''\n",
    "\n",
    "# Define the template and chain for enforcing CoT reasoning\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input_query\"],\n",
    "    template=system_prompt + \"\\nUser Query: {input_query}\"\n",
    ")\n",
    "\n",
    "local_llm = OllamaLLM(model=\"codeup\", temperature=0.2)\n",
    "\n",
    "# Updated chain configuration using pipe separator\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# Updated chain configuration using ToT\n",
    "class ToTChain(Chain):\n",
    "    \"\"\"Custom chain for handling Tree of Thought responses.\"\"\"\n",
    "    prompt: PromptTemplate\n",
    "    llm: OllamaLLM\n",
    "\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"input_query\"]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self):\n",
    "        return [\"output\"]\n",
    "\n",
    "    def _call(self, inputs: dict):\n",
    "        formatted_prompt = self.prompt.format(input_query=inputs[\"input_query\"])\n",
    "        response = self.llm.invoke(formatted_prompt)\n",
    "        return {\"output\": response}\n",
    "\n",
    "    def invoke(self, inputs: dict):\n",
    "        return self._call(inputs)\n",
    "\n",
    "# Iterative Chain of Thought Reasoning\n",
    "cot_chain = ToTChain(prompt=prompt_template, llm=local_llm)\n",
    "\n",
    "def run_tot_chain(query, max_steps=10):\n",
    "    branches = []\n",
    "    current_query = query\n",
    "    seen_responses = set()\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        result = cot_chain.invoke({\"input_query\": current_query})\n",
    "        try:\n",
    "            # Attempt to clean and parse the response\n",
    "            raw_output = result[\"output\"]\n",
    "            if \"%\" in raw_output:\n",
    "                raw_output = raw_output.replace(\"%\", \"\")  # Remove percentage signs\n",
    "            parsed_result = json.loads(raw_output)\n",
    "\n",
    "            # Append the parsed step to the reasoning tree\n",
    "            branches.append(parsed_result)\n",
    "\n",
    "            # Use high-confidence branches to guide further exploration\n",
    "            if parsed_result.get(\"confidence\", 0) > 80:\n",
    "                current_query = parsed_result[\"content\"] + \" What is the next step?\"\n",
    "\n",
    "            # Check for the final answer\n",
    "            if parsed_result.get(\"next_action\") == \"final_answer\":\n",
    "                break\n",
    "\n",
    "            # Detect repetition and avoid unnecessary loops\n",
    "            if parsed_result[\"content\"] in seen_responses:\n",
    "                current_query = \"Please provide the final answer based on your reasoning above.\"\n",
    "            else:\n",
    "                seen_responses.add(parsed_result[\"content\"])\n",
    "                current_query = parsed_result[\"content\"]\n",
    "            print(parsed_result[\"title\"])\n",
    "        except json.JSONDecodeError:\n",
    "            # Handle malformed JSON fallback\n",
    "            print(\"Error parsing response:\", result)\n",
    "            fallback_content = \"Fallback: Unable to parse response.\"\n",
    "            if \"content\" in result[\"output\"]:\n",
    "                fallback_content = result[\"output\"]\n",
    "            branches.append({\n",
    "                \"title\": \"Fallback Reasoning\",\n",
    "                \"content\": fallback_content,\n",
    "                \"confidence\": 50,\n",
    "                \"next_action\": \"continue\",\n",
    "            })\n",
    "            current_query = \"Please provide the final answer based on your reasoning above.\"\n",
    "\n",
    "    # Aggregate final results from high-confidence branches\n",
    "    final_results = [branch for branch in branches if branch.get(\"confidence\", 0) > 80]\n",
    "    return final_results if final_results else branches\n",
    "\n",
    "# Test the chain\n",
    "query = \"write hello world in python\"\n",
    "response_branches = run_tot_chain(query)\n",
    "for branch in response_branches:\n",
    "    print(json.dumps(branch, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be5e35-c4f9-40ff-aa1c-868dee74347d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
